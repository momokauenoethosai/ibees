#!/usr/bin/env python3
"""
Geminiå…¥å‡ºåŠ›ãƒ‡ãƒãƒƒã‚°ã‚·ã‚¹ãƒ†ãƒ 
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€é€ä¿¡ç”»åƒã€å¿œç­”çµæœã‚’ã™ã¹ã¦ä¿å­˜ãƒ»ç¢ºèªã™ã‚‹
"""

import json
import sys
import time
from pathlib import Path
from PIL import Image
import google.generativeai as genai

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))
from face_composer.face_composer import FaceComposer

# Geminiè¨­å®š
GEMINI_API_KEY = "AIzaSyAt-wzZ3WLU1fc6fnzHvDhPsTZJNKnHszU"
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash-exp')

def save_debug_session(
    session_id: str,
    iteration: int,
    prompt: str,
    images: list,
    response_text: str,
    adjustment_result: dict = None,
    error: str = None
):
    """ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è©³ç´°ä¿å­˜"""
    
    debug_dir = Path("outputs/debug_sessions") / session_id
    debug_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿å­˜
    prompt_file = debug_dir / f"iteration_{iteration}_prompt.txt"
    prompt_file.write_text(prompt, encoding='utf-8')
    
    # 2. é€ä¿¡ç”»åƒã‚’ä¿å­˜
    for i, image in enumerate(images):
        if isinstance(image, Image.Image):
            image_file = debug_dir / f"iteration_{iteration}_input_image_{i+1}.png"
            image.save(image_file)
    
    # 3. ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
    response_file = debug_dir / f"iteration_{iteration}_response.txt"
    response_file.write_text(response_text, encoding='utf-8')
    
    # 4. è§£æçµæœã‚’ä¿å­˜
    if adjustment_result:
        result_file = debug_dir / f"iteration_{iteration}_parsed_result.json"
        result_file.write_text(
            json.dumps(adjustment_result, ensure_ascii=False, indent=2),
            encoding='utf-8'
        )
    
    # 5. ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿å­˜
    if error:
        error_file = debug_dir / f"iteration_{iteration}_error.txt"
        error_file.write_text(f"ã‚¨ãƒ©ãƒ¼: {error}\n\nç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹:\n{response_text}", encoding='utf-8')
    
    # 6. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚µãƒãƒªãƒ¼ã‚’æ›´æ–°
    summary_file = debug_dir / "session_summary.json"
    
    summary_data = {}
    if summary_file.exists():
        try:
            summary_data = json.loads(summary_file.read_text(encoding='utf-8'))
        except:
            summary_data = {}
    
    summary_data[f"iteration_{iteration}"] = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "prompt_length": len(prompt),
        "images_sent": len(images),
        "response_length": len(response_text),
        "parsed_successfully": adjustment_result is not None,
        "similarity_score": adjustment_result.get('comparison_analysis', {}).get('similarity_score', 0.0) if adjustment_result else 0.0,
        "adjustments_count": len(adjustment_result.get('adjustments', {})) if adjustment_result else 0,
        "satisfied": adjustment_result.get('satisfied', False) if adjustment_result else False,
        "error": error
    }
    
    summary_file.write_text(
        json.dumps(summary_data, ensure_ascii=False, indent=2),
        encoding='utf-8'
    )
    
    print(f"ğŸ› ãƒ‡ãƒãƒƒã‚°ä¿å­˜: {debug_dir}")
    return debug_dir

def create_triple_image_prompt_with_debug(parts_list: list, iteration: int, adjustment_history: list) -> str:
    """ãƒ‡ãƒãƒƒã‚°æƒ…å ±ä»˜ãã®3ç”»åƒåˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    parts_str = ", ".join(parts_list)
    
    # èª¿æ•´å±¥æ­´ã®ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    history_text = ""
    if adjustment_history:
        history_text = f"\n## ğŸ“Š èª¿æ•´å±¥æ­´ï¼ˆ{len(adjustment_history)}å›å®Ÿæ–½ï¼‰\n"
        for i, hist in enumerate(adjustment_history, 1):
            similarity_change = hist.get('similarity_after', 0.0) - hist.get('similarity_before', 0.0)
            adjustments = hist.get('adjustments', {})
            
            history_text += f"**åå¾©{i}**: "
            if adjustments:
                adj_summary = ", ".join([f"{part}({adj.get('position', '')}{adj.get('scale', '')})" 
                                       for part, adj in adjustments.items()])
                history_text += f"{adj_summary} â†’ é¡ä¼¼åº¦å¤‰åŒ– {similarity_change:+.2f}\n"
            else:
                history_text += "èª¿æ•´ãªã—\n"
    
    return f"""
ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: åå¾©{iteration} - è©³ç´°åˆ†æ

3ã¤ã®é¡”ç”»åƒã‚’å³å¯†ã«æ¯”è¼ƒåˆ†æã—ã¦ãã ã•ã„ï¼š

## ğŸ“· ç”»åƒã®èª¬æ˜
**ç”»åƒ1**: å…ƒã®å®Ÿéš›ã®é¡”å†™çœŸï¼ˆæœ€çµ‚ç›®æ¨™ï¼‰
**ç”»åƒ2**: å‰å›åå¾©ã®ä¼¼é¡”çµµï¼ˆå‚è€ƒãƒ»æ¯”è¼ƒç”¨ï¼‰  
**ç”»åƒ3**: æœ€æ–°ã®ä¼¼é¡”çµµï¼ˆèª¿æ•´å¯¾è±¡ï¼‰

## ğŸ¯ ãƒ‡ãƒãƒƒã‚°é‡ç‚¹é …ç›®

### âš ï¸ äººé–“ãŒèªè­˜ã™ã‚‹ä¸è‡ªç„¶ã•ã®æ¤œå‡º
ä»¥ä¸‹ã®ç‚¹ã‚’ç‰¹ã«å³ã—ãè©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

1. **ç›®ã®é–“éš”ç•°å¸¸**: 
   - ç•°å¸¸ã«é›¢ã‚Œã¦ã„ã‚‹ï¼ˆé¡”å¹…ã®50%ä»¥ä¸Šï¼‰
   - ç•°å¸¸ã«è¿‘ã„ï¼ˆé¡”å¹…ã®20%æœªæº€ï¼‰

2. **ãƒ‘ãƒ¼ãƒ„ã‚µã‚¤ã‚ºç•°å¸¸**:
   - å£ãŒé¡”ã«å¯¾ã—ã¦ç•°å¸¸ã«å¤§ãã„ï¼ˆé¡”å¹…ã®40%ä»¥ä¸Šï¼‰
   - ç›®ãŒç•°å¸¸ã«å°ã•ã„/å¤§ãã„ï¼ˆãƒãƒ©ãƒ³ã‚¹å´©å£Šï¼‰

3. **ä½ç½®é–¢ä¿‚ç•°å¸¸**:
   - çœ‰ã¨ç›®ãŒç•°å¸¸ã«é›¢ã‚Œã¦ã„ã‚‹ï¼ˆè¦ªã—ã¿ã‚„ã™ã•çš†ç„¡ï¼‰
   - é¼»ã¨å£ãŒç•°å¸¸ã«é›¢ã‚Œã¦ã„ã‚‹ï¼ˆé–“å»¶ã³ï¼‰

### ğŸ“ æ•°å€¤çš„ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³
ç”»åƒ3ã§ä»¥ä¸‹ãŒç¢ºèªã•ã‚ŒãŸã‚‰ **å¼·åˆ¶ä¿®æ­£** ã—ã¦ãã ã•ã„ï¼š
- ç›®ã®å·¦å³é–“éš” > 80px â†’ `"eye": {{"position": "right"}}` ã§ç‹­ã‚ã‚‹
- å£ã‚µã‚¤ã‚º > é¡”å¹…35% â†’ `"mouth": {{"scale": "smaller"}}` ã§ç¸®å°
- çœ‰-ç›®è·é›¢ > 35px â†’ `"eyebrow": {{"position": "down"}}` ã§è¿‘ã¥ã‘ã‚‹
{history_text}

## ğŸ“‹ å¯¾è±¡ãƒ‘ãƒ¼ãƒ„: {parts_str}

## âš™ï¸ èª¿æ•´æŒ‡ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³
**ä½ç½®**: up, down, left, right (5px) / up_slight, down_slight, left_slight, right_slight (3px)
**ã‚µã‚¤ã‚º**: bigger, smaller (0.05å€) / bigger_slight, smaller_slight (0.03å€)

## ğŸ¯ **é‡è¦: äººé–“ã®æ„Ÿè¦šã«åˆã‚ã›ãŸå³æ ¼è©•ä¾¡**

ç”»åƒ3ã‚’è¦‹ã¦ã€äººé–“ãŒã€Œæ˜ã‚‰ã‹ã«ãŠã‹ã—ã„ã€ã¨æ„Ÿã˜ã‚‹éƒ¨åˆ†ãŒã‚ã‚Œã°ã€é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã«é–¢ä¿‚ãªã **å¼·åˆ¶ä¿®æ­£** ã—ã¦ãã ã•ã„ã€‚

**åˆ¤å®šåŸºæº–**:
- é¡ä¼¼åº¦0.7ã§ã‚‚æ˜ã‚‰ã‹ãªç•°å¸¸ãŒã‚ã‚Œã° â†’ satisfied: false
- é¡ä¼¼åº¦0.5ã§ã‚‚è‡ªç„¶ãªãƒãƒ©ãƒ³ã‚¹ãªã‚‰ â†’ satisfied: true

## å‡ºåŠ›å½¢å¼
```json
{{
  "debug_analysis": {{
    "human_perception_score": 0.3,
    "anomalies_detected": [
      "ç›®ã®é–“éš”ãŒç•°å¸¸ã«åºƒã„ï¼ˆç´„80pxï¼‰",
      "å£ãŒé¡”å…¨ä½“ã«å¯¾ã—ã¦ç•°å¸¸ã«å¤§ãã„"
    ]
  }},
  "comparison_analysis": {{
    "similarity_score": 0.4,
    "relationship_differences": [
      "ç”»åƒ1ã¨æ¯”è¼ƒã—ã¦ç”»åƒ3ã¯ç›®ãŒç•°å¸¸ã«é›¢ã‚Œã¦ãŠã‚Šä¸è‡ªç„¶",
      "ç”»åƒ1ã®è‡ªç„¶ãªå£ã‚µã‚¤ã‚ºã«å¯¾ã—ç”»åƒ3ã¯æ˜ã‚‰ã‹ã«å¤§ãã™ãã‚‹"
    ]
  }},
  "adjustments": {{
    "eye": {{"position": "right", "reason": "ç•°å¸¸ã«é›¢ã‚ŒãŸç›®ã®é–“éš”ã‚’äººé–“ã®æ„Ÿè¦šã«åˆã‚ã›ã¦ä¿®æ­£"}},
    "mouth": {{"scale": "smaller", "reason": "ç•°å¸¸ã«å¤§ãã„å£ã‚’è‡ªç„¶ãªã‚µã‚¤ã‚ºã«ä¿®æ­£"}}
  }},
  "satisfied": false,
  "notes": "äººé–“ã®æ„Ÿè¦šã§ã¯ä¸è‡ªç„¶ãªéƒ¨åˆ†ã‚’å„ªå…ˆçš„ã«ä¿®æ­£"
}}
```

**æœ€é‡è¦**: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã‚ˆã‚Š **äººé–“ãŒè¦‹ã¦è‡ªç„¶ã‹ã©ã†ã‹** ã‚’å„ªå…ˆã—ã¦ãã ã•ã„ã€‚
    """

def load_parts_from_json(json_path: str) -> dict:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ¼ãƒ„æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    
    def find_part_image_path(category: str, part_num: int) -> Path:
        assets_root = Path("kawakura/assets_png")
        category_mapping = {
            'mouth': 'mouse', 'hair': 'hair', 'eye': 'eye', 'eyebrow': 'eyebrow',
            'nose': 'nose', 'ear': 'ear', 'outline': 'outline', 'acc': 'acc',
            'beard': 'beard', 'glasses': 'glasses', 'extras': 'extras'
        }
        
        folder_name = category_mapping.get(category, category)
        category_folder = assets_root / folder_name
        file_prefix = folder_name
        
        candidates = [
            f"{file_prefix}_{part_num:03d}.png",
            f"{file_prefix}_{part_num:02d}.png", 
            f"{file_prefix}_{part_num}.png"
        ]
        
        for candidate in candidates:
            part_path = category_folder / candidate
            if part_path.exists():
                return part_path
        return None
    
    with open(json_path, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    parts_dict = {}
    parts = analysis_result.get('parts', {})
    
    for category, part_info in parts.items():
        selected = part_info.get('selected', {})
        part_num = selected.get('part_num')
        score = selected.get('score', 0.0)
        
        if part_num:
            part_image_path = find_part_image_path(category, part_num)
            if part_image_path:
                parts_dict[category] = {
                    'part_id': f"{category}_{part_num:03d}",
                    'image_path': part_image_path,
                    'part_num': part_num,
                    'score': score
                }
    
    return parts_dict

def get_original_image_path(json_path: str) -> Path:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…ƒç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    with open(json_path, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    input_image = analysis_result.get('input_image', '')
    
    if input_image.startswith('/Users/'):
        original_path = Path(input_image)
    else:
        original_path = Path(input_image)
    
    if not original_path.exists():
        filename = Path(input_image).name
        for search_dir in ["uploads", "made_pictures"]:
            candidate = Path(search_dir) / filename
            if candidate.exists():
                return candidate
    
    return original_path if original_path.exists() else None

def debug_gemini_io_test(json_path: str):
    """Geminiå…¥å‡ºåŠ›ã®ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆ"""
    
    session_id = f"debug_{time.strftime('%Y%m%d_%H%M%S')}"
    print(f"ğŸ› Gemini I/O ãƒ‡ãƒãƒƒã‚°ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹")
    print(f"ğŸ“‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}")
    print(f"ğŸ“„ JSONãƒ•ã‚¡ã‚¤ãƒ«: {json_path}")
    
    # 1. å…ƒç”»åƒã¨ãƒ‘ãƒ¼ãƒ„æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
    try:
        original_image_path = get_original_image_path(json_path)
        if not original_image_path or not original_image_path.exists():
            print(f"âŒ å…ƒç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_image_path}")
            return
        
        original_image = Image.open(original_image_path).resize((400, 400), Image.LANCZOS)
        print(f"ğŸ“¸ å…ƒç”»åƒ: {original_image_path} â†’ ãƒªã‚µã‚¤ã‚º(400x400)")
        
        parts_dict = load_parts_from_json(json_path)
        print(f"âœ… {len(parts_dict)}å€‹ã®ãƒ‘ãƒ¼ãƒ„èª­ã¿è¾¼ã¿: {list(parts_dict.keys())}")
        
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 2. åˆæœŸåº§æ¨™ã§åˆæˆ
    initial_positions = {
        'hair': (200, 200, 1.0),
        'eye': {'left': (225, 215, 0.2), 'right': (175, 215, 0.2)},
        'eyebrow': {'left': (225, 185, 0.2), 'right': (175, 185, 0.2)},
        'nose': (200, 230, 0.2),
        'mouth': (200, 255, 0.25),
        'ear': {'left': (250, 220, 0.28), 'right': (150, 220, 0.28)},
        'outline': (200, 200, 1.0),
        'acc': (200, 180, 0.3),
        'beard': (200, 300, 0.4),
        'glasses': (200, 215, 0.5)
    }
    
    print("\nğŸ¨ åˆæœŸåˆæˆå®Ÿè¡Œä¸­...")
    composer = FaceComposer(canvas_size=(400, 400))
    
    try:
        composed_image = composer.compose_face_with_custom_positions(
            base_image_path=None,
            parts_dict=parts_dict,
            custom_positions=initial_positions
        )
        
        if not composed_image:
            print("âŒ åˆæˆå¤±æ•—")
            return
        
        # RGBå¤‰æ›ã¨ãƒªã‚µã‚¤ã‚º
        if composed_image.mode == 'RGBA':
            background = Image.new('RGB', composed_image.size, (255, 255, 255))
            background.paste(composed_image, mask=composed_image.split()[-1])
            composed_image = background
        
        current_image = composed_image.resize((400, 400), Image.LANCZOS)
        
        # åˆæˆç”»åƒã‚’ä¿å­˜
        composed_path = Path("outputs") / f"debug_composed_{session_id}.png"
        current_image.save(composed_path)
        print(f"ğŸ’¾ åˆæˆç”»åƒ: {composed_path}")
        
    except Exception as e:
        print(f"âŒ åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 3. ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    print("\nğŸ“ ãƒ‡ãƒãƒƒã‚°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆä¸­...")
    prompt = create_triple_image_prompt_with_debug(list(parts_dict.keys()), 1, [])
    
    print(f"ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·: {len(prompt)}æ–‡å­—")
    print(f"ğŸ“· é€ä¿¡ç”»åƒ: å…ƒç”»åƒ(400x400) + åˆæˆç”»åƒ(400x400)")
    
    # 4. Geminiåˆ†æå®Ÿè¡Œ
    print("\nğŸ¤– Geminiåˆ†æå®Ÿè¡Œä¸­...")
    
    try:
        # é€ä¿¡ãƒ‡ãƒ¼ã‚¿
        gemini_input = [prompt, original_image, current_image]
        
        start_time = time.time()
        response = model.generate_content(gemini_input)
        end_time = time.time()
        
        response_text = response.text if response.text else "å¿œç­”ãªã—"
        analysis_time = end_time - start_time
        
        print(f"âœ… Geminiå¿œç­”å–å¾—: {analysis_time:.1f}ç§’")
        print(f"ğŸ“ å¿œç­”é•·: {len(response_text)}æ–‡å­—")
        print(f"ğŸ“‹ å¿œç­”ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:\n{response_text[:300]}...")
        
        # 5. JSONè§£æè©¦è¡Œ
        adjustment_result = None
        error = None
        
        try:
            # JSONè§£æ
            response_text_clean = response_text.strip()
            if '```json' in response_text_clean:
                start_idx = response_text_clean.find('```json') + 7
                end_idx = response_text_clean.find('```', start_idx)
                code_block = response_text_clean[start_idx:end_idx].strip()
            else:
                code_block = response_text_clean
            
            adjustment_result = json.loads(code_block)
            
            print(f"\nâœ… JSONè§£ææˆåŠŸ:")
            print(f"  é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {adjustment_result.get('comparison_analysis', {}).get('similarity_score', 'N/A')}")
            print(f"  äººé–“æ„Ÿè¦šã‚¹ã‚³ã‚¢: {adjustment_result.get('debug_analysis', {}).get('human_perception_score', 'N/A')}")
            print(f"  èª¿æ•´æ•°: {len(adjustment_result.get('adjustments', {}))}")
            print(f"  æº€è¶³åº¦: {adjustment_result.get('satisfied', False)}")
            
        except Exception as e:
            error = f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}"
            print(f"âŒ {error}")
        
        # 6. ãƒ‡ãƒãƒƒã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        debug_dir = save_debug_session(
            session_id=session_id,
            iteration=1,
            prompt=prompt,
            images=[original_image, current_image],
            response_text=response_text,
            adjustment_result=adjustment_result,
            error=error
        )
        
        print(f"\nğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:")
        print(f"  ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {debug_dir}/iteration_1_prompt.txt")
        print(f"  å…¥åŠ›ç”»åƒ: {debug_dir}/iteration_1_input_image_*.png")
        print(f"  ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {debug_dir}/iteration_1_response.txt")
        if adjustment_result:
            print(f"  è§£æçµæœ: {debug_dir}/iteration_1_parsed_result.json")
        print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦: {debug_dir}/session_summary.json")
        
    except Exception as e:
        error = f"Geminiå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}"
        print(f"âŒ {error}")
        
        # ã‚¨ãƒ©ãƒ¼ã‚‚ãƒ‡ãƒãƒƒã‚°ä¿å­˜
        save_debug_session(
            session_id=session_id,
            iteration=1,
            prompt=prompt,
            images=[original_image, current_image],
            response_text="",
            error=error
        )

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ³•:")
        print("  python debug_gemini_io.py <json_path>")
        print("\nä¾‹:")
        print("  python debug_gemini_io.py outputs/run_20250830_170700.json")
        
        json_files = list(Path("outputs").glob("run_*.json"))
        if json_files:
            print(f"\nğŸ“ åˆ©ç”¨å¯èƒ½ãªJSONãƒ•ã‚¡ã‚¤ãƒ«:")
            for f in sorted(json_files)[-3:]:
                print(f"  {f}")
        return
    
    json_path = sys.argv[1]
    debug_gemini_io_test(json_path)

if __name__ == "__main__":
    main()
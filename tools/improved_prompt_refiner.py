#!/usr/bin/env python3
"""
æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹åå¾©èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 
åº§æ¨™è§£é‡ˆã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ã€å·¦å³å¯¾ç§°ãƒ‘ãƒ¼ãƒ„ã«ç‰¹åŒ–ã—ãŸæŒ‡ç¤ºã‚’è¿½åŠ 
"""

import json
import sys
import time
from pathlib import Path
from PIL import Image
import google.generativeai as genai

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))
from face_composer.face_composer import FaceComposer

# Geminiè¨­å®š
GEMINI_API_KEY = "AIzaSyAt-wzZ3WLU1fc6fnzHvDhPsTZJNKnHszU"
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.0-flash-exp')

# æ”¹è‰¯ã•ã‚ŒãŸèª¿æ•´ã‚¹ãƒ†ãƒƒãƒ—
ADJUSTMENT_STEPS = {
    'position': {
        'up': (0, -5), 'down': (0, 5),
        'up_slight': (0, -3), 'down_slight': (0, 3)
    },
    'scale': {
        'bigger': 0.05, 'smaller': -0.05, 
        'bigger_slight': 0.03, 'smaller_slight': -0.03
    },
    'symmetrical': {
        # å·¦å³å¯¾ç§°ãƒ‘ãƒ¼ãƒ„å°‚ç”¨
        'closer': (-3, +3),  # å·¦ç›®ã‚’å³ã«ã€å³ç›®ã‚’å·¦ã«
        'wider': (+3, -3),   # å·¦ç›®ã‚’å·¦ã«ã€å³ç›®ã‚’å³ã«
        'closer_big': (-5, +5),  # å¤§ããé–“éš”èª¿æ•´
        'wider_big': (+5, -5)
    }
}

def create_improved_prompt(parts_list: list, iteration: int, adjustment_history: list) -> str:
    """åº§æ¨™è§£é‡ˆã‚¨ãƒ©ãƒ¼ã‚’ä¿®æ­£ã—ãŸæ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
    parts_str = ", ".join(parts_list)
    
    # èª¿æ•´å±¥æ­´ã®ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    history_text = ""
    if adjustment_history:
        history_text = f"\n## ğŸ“Š èª¿æ•´å±¥æ­´ï¼ˆ{len(adjustment_history)}å›å®Ÿæ–½ï¼‰\n"
        for i, hist in enumerate(adjustment_history, 1):
            similarity_change = hist.get('similarity_after', 0.0) - hist.get('similarity_before', 0.0)
            adjustments = hist.get('adjustments', {})
            human_score = hist.get('human_perception_score', 0.0)
            
            history_text += f"**åå¾©{i}**: "
            if adjustments:
                adj_summary = ", ".join([f"{part}({adj.get('position', '')}{adj.get('scale', '')}{adj.get('symmetrical', '')})" 
                                       for part, adj in adjustments.items()])
                history_text += f"{adj_summary}\n"
                history_text += f"  â†’ é¡ä¼¼åº¦: {hist.get('similarity_before', 0.0):.2f}â†’{hist.get('similarity_after', 0.0):.2f} / äººé–“æ„Ÿè¦š: {human_score:.2f}\n"
            else:
                history_text += "èª¿æ•´ãªã—\n"
    
    return f"""
ğŸ”§ æ”¹è‰¯ç‰ˆåº§æ¨™èª¿æ•´åˆ†æ - åå¾©{iteration}

## ğŸ“· ç”»åƒåˆ†æ
æä¾›ã•ã‚ŒãŸç”»åƒã‚’åˆ†æã—ã€äººé–“ãŒè‡ªç„¶ã¨æ„Ÿã˜ã‚‹é¡”ãƒãƒ©ãƒ³ã‚¹ã«èª¿æ•´ã—ã¦ãã ã•ã„ã€‚

{history_text}

## âš ï¸ é‡è¦ï¼šåº§æ¨™è§£é‡ˆã®æ­£ç¢ºãªç†è§£

### ğŸ¯ å·¦å³å¯¾ç§°ãƒ‘ãƒ¼ãƒ„ï¼ˆeye, eyebrow, earï¼‰ã®ç‰¹æ®ŠæŒ‡ç¤º
**é–“éš”èª¿æ•´ï¼ˆæœ€é‡è¦ï¼‰**:
- `"eye": {{"symmetrical": "closer"}}` â†’ å·¦ç›®ã‚’å³ã«ã€å³ç›®ã‚’å·¦ã«ç§»å‹•ï¼ˆé–“éš”ã‚’ç‹­ã‚ã‚‹ï¼‰
- `"eye": {{"symmetrical": "wider"}}` â†’ å·¦ç›®ã‚’å·¦ã«ã€å³ç›®ã‚’å³ã«ç§»å‹•ï¼ˆé–“éš”ã‚’åºƒã’ã‚‹ï¼‰
- `"eye": {{"symmetrical": "closer_big"}}` â†’ é–“éš”ã‚’å¤§å¹…ã«ç‹­ã‚ã‚‹ï¼ˆ5pxï¼‰
- `"eye": {{"symmetrical": "wider_big"}}` â†’ é–“éš”ã‚’å¤§å¹…ã«åºƒã’ã‚‹ï¼ˆ5pxï¼‰

**å€‹åˆ¥ç§»å‹•**:
- `"eye": {{"position": "up"}}` â†’ å·¦å³ä¸¡æ–¹ã®ç›®ã‚’ä¸Šã«ç§»å‹•
- `"eye": {{"position": "down"}}` â†’ å·¦å³ä¸¡æ–¹ã®ç›®ã‚’ä¸‹ã«ç§»å‹•

### ğŸ“ å˜ä¸€ãƒ‘ãƒ¼ãƒ„ã®åº§æ¨™ç³»
- **upç§»å‹•**: ç”»é¢ä¸Šéƒ¨ã«ç§»å‹•ï¼ˆyå€¤æ¸›å°‘ï¼‰
- **downç§»å‹•**: ç”»é¢ä¸‹éƒ¨ã«ç§»å‹•ï¼ˆyå€¤å¢—åŠ ï¼‰

## ğŸš¨ è§£å‰–å­¦çš„ç•°å¸¸ã®å¼·åˆ¶æ¤œå‡º

### ç¾åœ¨ã®åº§æ¨™å€¤ï¼ˆå‚è€ƒï¼‰
- eye_left: (225, 215), eye_right: (175, 215) â†’ **é–“éš”50px**
- eyebrow_left: (225, 185), eyebrow_right: (175, 185) â†’ **çœ‰ã¨ç›®ã®è·é›¢30px**

### ğŸ“ å³æ ¼ãªè‡ªç„¶ã•åˆ¤å®šåŸºæº–

#### ğŸ¯ **satisfied=true** ã®å³ã—ã„æ¡ä»¶ï¼ˆALLå¿…é ˆï¼‰
1. **ç›®ã®é–“éš”**: 32-60pxï¼ˆé»„é‡‘æ¯”ï¼‰
2. **çœ‰ã¨ç›®ã®è·é›¢**: 10-40pxï¼ˆè¦ªè¿‘æ„Ÿã®ã‚ã‚‹è‡ªç„¶ã•ï¼‰
3. **é¼»ã¨å£ã®è·é›¢**: 10-40pxï¼ˆä¸­é¡”é¢ã®èª¿å’Œï¼‰
4. **å£ã®ã‚µã‚¤ã‚º**: scale 0.18-0.35ï¼ˆé¡”å…¨ä½“ã¨ã®èª¿å’Œï¼‰
5. **human_perception_score**: 0.95ä»¥ä¸Šï¼ˆéå¸¸ã«è‡ªç„¶ï¼‰
6. **å…ƒç”»åƒã¨ã®å°è±¡**: é¡”ã®é›°å›²æ°—ãƒ»è¡¨æƒ…ãŒååˆ†é¡ä¼¼

#### ğŸš« **satisfied=false** ã®æ¡ä»¶ï¼ˆ1ã¤ã§ã‚‚è©²å½“ã§ç¶™ç¶šï¼‰
- ç›®ã®é–“éš”ãŒ50pxä»¥ä¸Šã¾ãŸã¯40pxæœªæº€
- çœ‰ã¨ç›®ã®è·é›¢ãŒ28pxä»¥ä¸Šã¾ãŸã¯15pxæœªæº€  
- é¼»ã¨å£ã®è·é›¢ãŒ35pxä»¥ä¸Šã¾ãŸã¯18pxæœªæº€
- å£ã®scaleãŒ0.32ä»¥ä¸Šã¾ãŸã¯0.15æœªæº€
- human_perception_score ãŒ 0.8æœªæº€
- ãƒ‘ãƒ¼ãƒ„é…ç½®ãƒ»æ¯”ç‡ã«é•å’Œæ„Ÿã‚ã‚Š

#### âš ï¸ **ç•°å¸¸ãƒ¬ãƒ™ãƒ«ï¼ˆå¼·åˆ¶ä¿®æ­£å¿…è¦ï¼‰**
- ç›®ã®é–“éš”80pxä»¥ä¸Š â†’ å³åº§ã« `symmetrical: closer_big`
- å£ã®scale 0.45ä»¥ä¸Š â†’ å³åº§ã« `scale: smaller`
- çœ‰ã¨ç›®ã®è·é›¢60pxä»¥ä¸Š â†’ å³åº§ã« `position: down`

## ğŸ“‹ å¯¾è±¡ãƒ‘ãƒ¼ãƒ„: {parts_str}

## âš™ï¸ èª¿æ•´æŒ‡ç¤ºã‚ªãƒ—ã‚·ãƒ§ãƒ³

### ä½ç½®èª¿æ•´
- **å˜ä¸€ãƒ‘ãƒ¼ãƒ„**: up, down, up_slight, down_slight
- **å¯¾ç§°ãƒ‘ãƒ¼ãƒ„ã®é–“éš”**: closer, wider, closer_big, wider_big

### ã‚µã‚¤ã‚ºèª¿æ•´  
- bigger, smaller, bigger_slight, smaller_slight

## ğŸ¯ èª¿æ•´ä¾‹ï¼ˆæ­£ç¢ºãªè§£é‡ˆï¼‰

**âŒ é–“é•ã£ãŸæŒ‡ç¤º**:
- `"eye": {{"position": "right"}}` â†’ ä¸¡ç›®ãŒå³ã«ç§»å‹•ï¼ˆé–“éš”å¤‰ã‚ã‚‰ãšï¼‰

**âœ… æ­£ã—ã„æŒ‡ç¤º**:
- `"eye": {{"symmetrical": "closer"}}` â†’ å·¦ç›®ãŒå³ã«ã€å³ç›®ãŒå·¦ã«ï¼ˆé–“éš”ãŒç‹­ã¾ã‚‹ï¼‰
- `"eye": {{"symmetrical": "wider"}}` â†’ å·¦ç›®ãŒå·¦ã«ã€å³ç›®ãŒå³ã«ï¼ˆé–“éš”ãŒåºƒãŒã‚‹ï¼‰

## å‡ºåŠ›å½¢å¼
```json
{{
  "debug_analysis": {{
    "human_perception_score": 0.6,
    "current_measurements": {{
      "eye_distance": "50pxï¼ˆç†æƒ³42-48pxã€åŸºæº–å¤–ã®ãŸã‚è¦èª¿æ•´ï¼‰",
      "eyebrow_eye_gap": "30pxï¼ˆç†æƒ³18-25pxã€åŸºæº–å¤–ã®ãŸã‚è¦èª¿æ•´ï¼‰",
      "nose_mouth_gap": "25pxï¼ˆç†æƒ³20-30pxã€è¨±å®¹ç¯„å›²ï¼‰",
      "mouth_scale": "0.25ï¼ˆç†æƒ³0.18-0.28ã€è¨±å®¹ç¯„å›²ï¼‰"
    }},
    "fails_satisfaction_criteria": [
      "ç›®ã®é–“éš”50pxãŒç†æƒ³ç¯„å›²42-48pxã‚’è¶…é",
      "çœ‰ã¨ç›®ã®è·é›¢30pxãŒç†æƒ³ç¯„å›²18-25pxã‚’è¶…é",
      "human_perception_score 0.6ãŒæœ€ä½åŸºæº–0.85æœªæº€"
    ]
  }},
  "adjustments": {{
    "eye": {{"symmetrical": "closer", "reason": "50pxâ†’45pxç¨‹åº¦ã«ç‹­ã‚ã¦ç†æƒ³ç¯„å›²ã«"}},
    "eyebrow": {{"position": "down", "reason": "30pxâ†’23pxç¨‹åº¦ã«ç¸®ã‚ã¦è¦ªè¿‘æ„Ÿå‘ä¸Š"}}
  }},
  "satisfied": false,
  "notes": "å³æ ¼åŸºæº–ã«ã‚ˆã‚Šç¶™ç¶šèª¿æ•´ãŒå¿…è¦ï¼šç›®é–“éš”ã¨çœ‰ä½ç½®ãŒç†æƒ³ç¯„å›²å¤–"
}}
```

**é‡è¦**: satisfied=trueã¯éå¸¸ã«å³ã—ã„åŸºæº–ã§ã™ã€‚å°‘ã—ã§ã‚‚ç†æƒ³ç¯„å›²ã‚’å¤–ã‚ŒãŸã‚‰ false ã§ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚

**æœ€é‡è¦**: 
1. ç›®ã®é–“éš”èª¿æ•´ã¯å¿…ãš `symmetrical` ã‚’ä½¿ç”¨
2. åº§æ¨™å€¤ã¨äººé–“ã®æ„Ÿè¦šã‚’ä¸¡æ–¹è€ƒæ…®
3. ç•°å¸¸å€¤ï¼ˆç›®é–“éš”70px+, å£scale0.4+ï¼‰ã¯å¼·åˆ¶ä¿®æ­£
    """

def load_parts_from_json(json_path: str) -> dict:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ¼ãƒ„æƒ…å ±ã‚’èª­ã¿è¾¼ã¿"""
    
    def find_part_image_path(category: str, part_num: int) -> Path:
        assets_root = Path("kawakura/assets_png")
        category_mapping = {
            'mouth': 'mouse', 'hair': 'hair', 'eye': 'eye', 'eyebrow': 'eyebrow',
            'nose': 'nose', 'ear': 'ear', 'outline': 'outline', 'acc': 'acc',
            'beard': 'beard', 'glasses': 'glasses', 'extras': 'extras'
        }
        
        folder_name = category_mapping.get(category, category)
        category_folder = assets_root / folder_name
        file_prefix = folder_name
        
        candidates = [
            f"{file_prefix}_{part_num:03d}.png",
            f"{file_prefix}_{part_num:02d}.png", 
            f"{file_prefix}_{part_num}.png"
        ]
        
        for candidate in candidates:
            part_path = category_folder / candidate
            if part_path.exists():
                return part_path
        return None
    
    with open(json_path, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    parts_dict = {}
    parts = analysis_result.get('parts', {})
    
    for category, part_info in parts.items():
        selected = part_info.get('selected', {})
        part_num = selected.get('part_num')
        score = selected.get('score', 0.0)
        
        if part_num:
            part_image_path = find_part_image_path(category, part_num)
            if part_image_path:
                parts_dict[category] = {
                    'part_id': f"{category}_{part_num:03d}",
                    'image_path': part_image_path,
                    'part_num': part_num,
                    'score': score
                }
    
    return parts_dict

def get_original_image_path(json_path: str) -> Path:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å…ƒç”»åƒã®ãƒ‘ã‚¹ã‚’å–å¾—"""
    with open(json_path, 'r', encoding='utf-8') as f:
        analysis_result = json.load(f)
    
    input_image = analysis_result.get('input_image', '')
    
    if input_image.startswith('/Users/'):
        original_path = Path(input_image)
    else:
        original_path = Path(input_image)
    
    if not original_path.exists():
        filename = Path(input_image).name
        for search_dir in ["uploads", "made_pictures"]:
            candidate = Path(search_dir) / filename
            if candidate.exists():
                return candidate
    
    return original_path if original_path.exists() else None

def apply_improved_adjustments(current_positions: dict, adjustments: dict) -> dict:
    """æ”¹è‰¯ã•ã‚ŒãŸèª¿æ•´ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå·¦å³å¯¾ç§°ãƒ‘ãƒ¼ãƒ„å¯¾å¿œï¼‰"""
    new_positions = json.loads(json.dumps(current_positions))
    
    for category, adj_info in adjustments.items():
        if category not in new_positions:
            continue
            
        pos_adj = adj_info.get('position')
        scale_adj = adj_info.get('scale')
        symmetrical_adj = adj_info.get('symmetrical')
        reason = adj_info.get('reason', '')
        current_pos = new_positions[category]
        
        if isinstance(current_pos, dict) and ('left' in current_pos and 'right' in current_pos):
            # å·¦å³å¯¾ç§°ãƒ‘ãƒ¼ãƒ„ã®å‡¦ç†
            left_x, left_y, left_scale = current_pos['left']
            right_x, right_y, right_scale = current_pos['right']
            
            # å¯¾ç§°èª¿æ•´ï¼ˆé–“éš”å¤‰æ›´ï¼‰
            if symmetrical_adj and symmetrical_adj in ADJUSTMENT_STEPS['symmetrical']:
                left_dx, right_dx = ADJUSTMENT_STEPS['symmetrical'][symmetrical_adj]
                new_left_x = left_x + left_dx
                new_right_x = right_x + right_dx
                
                new_positions[category]['left'] = (new_left_x, left_y, left_scale)
                new_positions[category]['right'] = (new_right_x, right_y, right_scale)
                
                old_distance = abs(left_x - right_x)
                new_distance = abs(new_left_x - new_right_x)
                print(f"  [SYMMETRICAL] {category}: {symmetrical_adj} - é–“éš”{old_distance}pxâ†’{new_distance}px")
            
            # é€šå¸¸ã®ä½ç½®èª¿æ•´ï¼ˆä¸¡æ–¹åŒæ™‚ç§»å‹•ï¼‰
            elif pos_adj and pos_adj in ADJUSTMENT_STEPS['position']:
                dx, dy = ADJUSTMENT_STEPS['position'][pos_adj]
                new_positions[category]['left'] = (left_x + dx, left_y + dy, left_scale)
                new_positions[category]['right'] = (right_x + dx, right_y + dy, right_scale)
                print(f"  [POSITION] {category}: {pos_adj} - ä¸¡æ–¹ã‚’({dx}, {dy})ç§»å‹•")
            
            # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
            if scale_adj and scale_adj in ADJUSTMENT_STEPS['scale']:
                scale_delta = ADJUSTMENT_STEPS['scale'][scale_adj]
                new_left_scale = max(0.1, min(1.0, left_scale + scale_delta))
                new_right_scale = max(0.1, min(1.0, right_scale + scale_delta))
                
                new_positions[category]['left'] = (new_positions[category]['left'][0], new_positions[category]['left'][1], new_left_scale)
                new_positions[category]['right'] = (new_positions[category]['right'][0], new_positions[category]['right'][1], new_right_scale)
                print(f"  [SCALE] {category}: {scale_adj} - scale {left_scale:.2f}â†’{new_left_scale:.2f}")
            
        else:
            # å˜ä¸€ãƒ‘ãƒ¼ãƒ„ã®å‡¦ç†
            if len(current_pos) >= 3:
                x, y, scale = current_pos
                
                # ä½ç½®èª¿æ•´
                if pos_adj and pos_adj in ADJUSTMENT_STEPS['position']:
                    dx, dy = ADJUSTMENT_STEPS['position'][pos_adj]
                    x, y = x + dx, y + dy
                
                # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
                if scale_adj and scale_adj in ADJUSTMENT_STEPS['scale']:
                    scale_delta = ADJUSTMENT_STEPS['scale'][scale_adj]
                    scale = max(0.1, min(1.0, scale + scale_delta))
                
                new_positions[category] = (x, y, scale)
                print(f"  [SINGLE] {category}: {adj_info} â†’ ({x}, {y}, {scale:.2f})")
        
        print(f"    ç†ç”±: {reason}")
    
    return new_positions

def improved_refinement_test(json_path: str, max_iterations: int = 5):
    """æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹åå¾©èª¿æ•´ãƒ†ã‚¹ãƒˆ"""
    
    session_id = f"improved_{time.strftime('%Y%m%d_%H%M%S')}"
    print(f"ğŸš€ æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåå¾©èª¿æ•´ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print(f"ğŸ†” ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {session_id}")
    print(f"ğŸ“„ JSONãƒ•ã‚¡ã‚¤ãƒ«: {json_path}")
    
    # 1. å…ƒç”»åƒã¨ãƒ‘ãƒ¼ãƒ„æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
    try:
        original_image_path = get_original_image_path(json_path)
        if not original_image_path or not original_image_path.exists():
            print(f"âŒ å…ƒç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_image_path}")
            return
        
        original_image = Image.open(original_image_path).resize((400, 400), Image.LANCZOS)
        print(f"ğŸ“¸ å…ƒç”»åƒ: {original_image_path}")
        
        parts_dict = load_parts_from_json(json_path)
        print(f"âœ… {len(parts_dict)}å€‹ã®ãƒ‘ãƒ¼ãƒ„èª­ã¿è¾¼ã¿: {list(parts_dict.keys())}")
        
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # 2. åˆæœŸåº§æ¨™ï¼ˆå•é¡Œã®ã‚ã‚‹è¨­å®šã§é–‹å§‹ï¼‰
    current_positions = {
        'hair': (200, 200, 1.0),
        'eye': {'left': (225, 215, 0.2), 'right': (175, 215, 0.2)},  # 50pxé–“éš”
        'eyebrow': {'left': (225, 185, 0.2), 'right': (175, 185, 0.2)},
        'nose': (200, 230, 0.2),
        'mouth': (200, 255, 0.25),  # ã‚„ã‚„å¤§ãã‚
        'ear': {'left': (250, 220, 0.28), 'right': (150, 220, 0.28)},
        'outline': (200, 200, 1.0),
        'acc': (200, 180, 0.3),
        'beard': (200, 300, 0.4),
        'glasses': (200, 215, 0.5)
    }
    
    # åˆæœŸçŠ¶æ…‹ã®åº§æ¨™åˆ†æ
    eye_distance = abs(current_positions['eye']['left'][0] - current_positions['eye']['right'][0])
    mouth_scale = current_positions['mouth'][2]
    print(f"ğŸ“ åˆæœŸçŠ¶æ…‹: ç›®ã®é–“éš”{eye_distance}px, å£scale{mouth_scale:.2f}")
    
    iteration_images = []
    adjustment_history = []
    composer = FaceComposer(canvas_size=(400, 400))
    start_time = time.time()
    
    # 3. åå¾©ãƒ«ãƒ¼ãƒ—
    for iteration in range(max_iterations):
        print(f"\n--- ğŸš€ åå¾© {iteration + 1}/{max_iterations} ï¼ˆæ”¹è‰¯ç‰ˆï¼‰---")
        
        # ç¾åœ¨ã®åº§æ¨™çŠ¶æ…‹ã‚’è¡¨ç¤º
        if 'eye' in current_positions:
            eye_left_x = current_positions['eye']['left'][0]
            eye_right_x = current_positions['eye']['right'][0]
            current_distance = abs(eye_left_x - eye_right_x)
            print(f"ğŸ“ ç¾åœ¨ã®ç›®é–“éš”: {current_distance}px ï¼ˆå·¦{eye_left_x}, å³{eye_right_x}ï¼‰")
        
        # 3.1 ç¾åœ¨åº§æ¨™ã§åˆæˆ
        print("ğŸ¨ åˆæˆä¸­...")
        try:
            composed_image = composer.compose_face_with_custom_positions(
                base_image_path=None,
                parts_dict=parts_dict,
                custom_positions=current_positions
            )
            
            if not composed_image:
                print(f"âŒ åå¾©{iteration + 1}: åˆæˆå¤±æ•—")
                break
            
            # RGBå¤‰æ›ã¨ãƒªã‚µã‚¤ã‚º
            if composed_image.mode == 'RGBA':
                background = Image.new('RGB', composed_image.size, (255, 255, 255))
                background.paste(composed_image, mask=composed_image.split()[-1])
                composed_image = background
            
            current_image = composed_image.resize((400, 400), Image.LANCZOS)
            
            # ç”»åƒä¿å­˜
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            iteration_filename = f"improved_{iteration + 1}_{timestamp}.png"
            iteration_path = Path("outputs") / iteration_filename
            current_image.save(iteration_path)
            iteration_images.append(current_image)
            print(f"ğŸ’¾ åå¾©ç”»åƒ: {iteration_path}")
            
        except Exception as e:
            print(f"âŒ åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
            break
        
        # 3.2 æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§Geminiåˆ†æ
        print(f"ğŸ¤–ğŸš€ Geminiæ”¹è‰¯åˆ†æä¸­ï¼ˆ{len(iteration_images)+1}ç”»åƒï¼‰...")
        try:
            prompt = create_improved_prompt(list(parts_dict.keys()), iteration + 1, adjustment_history)
            
            # å…¨å±¥æ­´ç”»åƒã‚’é€ä¿¡
            gemini_input = [prompt, original_image] + iteration_images
            
            print(f"ğŸ“· é€ä¿¡: å…ƒç”»åƒ + åå¾©1~{iteration+1} = è¨ˆ{len(gemini_input)-1}ç”»åƒ")
            
            response = model.generate_content(gemini_input)
            
            if not response.text:
                print(f"âŒ åå¾©{iteration + 1}: Geminiå¿œç­”ãªã—")
                break
            
            response_text = response.text
            print(f"ğŸ“‹ Geminiå¿œç­”: {len(response_text)}æ–‡å­—")
            
            # JSONè§£æ
            try:
                response_clean = response_text.strip()
                if '```json' in response_clean:
                    start_idx = response_clean.find('```json') + 7
                    end_idx = response_clean.find('```', start_idx)
                    code_block = response_clean[start_idx:end_idx].strip()
                else:
                    code_block = response_clean
                
                adjustment_result = json.loads(code_block)
                
                # çµæœç¢ºèª
                debug_analysis = adjustment_result.get('debug_analysis', {})
                human_score = debug_analysis.get('human_perception_score', 0.0)
                anomalies = debug_analysis.get('anomalies_detected', [])
                
                satisfied = adjustment_result.get('satisfied', False)
                adjustments = adjustment_result.get('adjustments', {})
                notes = adjustment_result.get('notes', '')
                
                print(f"\nğŸ“Š æ”¹è‰¯åˆ†æçµæœ:")
                print(f"  ğŸ­ äººé–“æ„Ÿè¦šã‚¹ã‚³ã‚¢: {human_score:.2f}")
                print(f"  ğŸš¨ æ¤œå‡ºç•°å¸¸: {anomalies}")
                print(f"  ğŸ˜Š æº€è¶³åº¦: {satisfied}")
                print(f"  ğŸ”§ èª¿æ•´æŒ‡ç¤º: {adjustments}")
                print(f"  ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆ: {notes}")
                
                # å±¥æ­´è¨˜éŒ²
                history_entry = {
                    'iteration': iteration + 1,
                    'similarity_before': 0.0 if iteration == 0 else adjustment_history[-1].get('similarity_after', 0.0),
                    'similarity_after': human_score,  # äººé–“æ„Ÿè¦šã‚¹ã‚³ã‚¢ã‚’é¡ä¼¼åº¦ã¨ã—ã¦ä½¿ç”¨
                    'human_perception_score': human_score,
                    'adjustments': adjustments,
                    'notes': notes,
                    'anomalies': anomalies
                }
                adjustment_history.append(history_entry)
                
                # æº€è¶³ã¾ãŸã¯èª¿æ•´ãªã—ãªã‚‰çµ‚äº†
                if satisfied or not adjustments:
                    print(f"âœ… åå¾©{iteration + 1}: ç›®æ¨™é”æˆï¼ï¼ˆäººé–“æ„Ÿè¦š: {human_score:.2f}ï¼‰")
                    break
                
                # æ”¹è‰¯ã•ã‚ŒãŸç›¸å¯¾èª¿æ•´ã‚’é©ç”¨
                print("âš™ï¸ æ”¹è‰¯èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ é©ç”¨ä¸­...")
                current_positions = apply_improved_adjustments(current_positions, adjustments)
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±æ•—: {e}")
                print(f"ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response_text}")
                break
                
        except Exception as e:
            print(f"âŒ Geminiå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    # 4. çµæœãƒ¬ãƒãƒ¼ãƒˆ
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"\nğŸ æ”¹è‰¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_time:.1f}ç§’")
    print(f"ğŸ–¼ï¸ ç”Ÿæˆç”»åƒæ•°: {len(iteration_images)}æš")
    print(f"ğŸ“ ä¿å­˜å…ˆ: outputs/improved_*.png")
    
    # æœ€çµ‚åº§æ¨™ç¢ºèª
    if 'eye' in current_positions:
        final_eye_distance = abs(current_positions['eye']['left'][0] - current_positions['eye']['right'][0])
        final_mouth_scale = current_positions['mouth'][2]
        print(f"\nğŸ“ æœ€çµ‚çŠ¶æ…‹:")
        print(f"  ç›®ã®é–“éš”: {eye_distance}px â†’ {final_eye_distance}px")
        print(f"  å£ã®scale: {mouth_scale:.2f} â†’ {final_mouth_scale:.2f}")
    
    if adjustment_history:
        print(f"\nğŸ“ˆ äººé–“æ„Ÿè¦šã‚¹ã‚³ã‚¢å¤‰åŒ–:")
        for hist in adjustment_history:
            score = hist.get('human_perception_score', 0.0)
            print(f"  åå¾©{hist['iteration']}: {score:.2f}")

def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ³•:")
        print("  python improved_prompt_refiner.py <json_path> [max_iterations]")
        print("\nä¾‹:")
        print("  python improved_prompt_refiner.py outputs/run_20250830_170700.json")
        print("  python improved_prompt_refiner.py outputs/run_20250830_170700.json 3")
        return
    
    json_path = sys.argv[1]
    max_iterations = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    
    improved_refinement_test(json_path, max_iterations)

if __name__ == "__main__":
    main()